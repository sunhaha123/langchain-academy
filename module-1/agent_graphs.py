"""
LangGraph Studio å›¾å®šä¹‰æ–‡ä»¶
å°† agent-memory.ipynb ä¸­çš„å›¾å¯¼å‡ºä¸ºå¯å¯¼å…¥çš„ Python æ¨¡å—
"""

import os
from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥å¿…éœ€çš„åº“
from langchain_openai import ChatOpenAI
from langgraph.graph import MessagesState, START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import SystemMessage

# è·å–ä»£ç†
proxy = os.environ.get("PROXY")

# å®šä¹‰å·¥å…·
def multiply(a: int, b: int) -> int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

def add(a: int, b: int) -> int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -> float:
    """Divide a and b.

    Args:
        a: first int
        b: second int
    """
    return a / b

# å·¥å…·åˆ—è¡¨
tools = [add, multiply, divide]

# åˆ›å»º LLM
llm = ChatOpenAI(model="gpt-4o", openai_proxy=f"http://{proxy}" if proxy else None)
llm_with_tools = llm.bind_tools(tools)

# ç³»ç»Ÿæ¶ˆæ¯
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# åŠ©æ‰‹èŠ‚ç‚¹
def assistant(state: MessagesState):
    return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# åˆ›å»ºåŸºç¡€å›¾ï¼ˆæ— è®°å¿†ï¼‰
def create_basic_graph():
    """åˆ›å»ºåŸºç¡€çš„ React å›¾ï¼ˆæ— è®°å¿†ï¼‰"""
    builder = StateGraph(MessagesState)
    
    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("assistant", assistant)
    builder.add_node("tools", ToolNode(tools))
    
    # æ·»åŠ è¾¹
    builder.add_edge(START, "assistant")
    builder.add_conditional_edges(
        "assistant",
        tools_condition,
    )
    builder.add_edge("tools", "assistant")
    
    return builder.compile()

# åˆ›å»ºå¸¦è®°å¿†çš„å›¾ (LangGraph APIæœåŠ¡å™¨ä¼šè‡ªåŠ¨æä¾›æŒä¹…åŒ–)
def create_memory_graph():
    """åˆ›å»ºå¸¦è®°å¿†çš„ React å›¾ - APIæœåŠ¡å™¨è‡ªåŠ¨å¤„ç†æŒä¹…åŒ–"""
    builder = StateGraph(MessagesState)
    
    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("assistant", assistant)
    builder.add_node("tools", ToolNode(tools))
    
    # æ·»åŠ è¾¹
    builder.add_edge(START, "assistant")
    builder.add_conditional_edges(
        "assistant",
        tools_condition,
    )
    builder.add_edge("tools", "assistant")
    
    # ä¸ä½¿ç”¨è‡ªå®šä¹‰checkpointer - APIæœåŠ¡å™¨ä¼šè‡ªåŠ¨å¤„ç†æŒä¹…åŒ–
    return builder.compile()

# å¯¼å‡ºçš„å›¾å¯¹è±¡ï¼ˆStudio ä¼šå¯¼å…¥è¿™äº›ï¼‰
react_graph = create_basic_graph()
react_graph_memory = create_memory_graph()

# ä¸ºäº† Studio çš„å…¼å®¹æ€§ï¼Œä¹Ÿå¯ä»¥ç›´æ¥èµ‹å€¼
basic_agent = react_graph
memory_agent = react_graph_memory

if __name__ == "__main__":
    # æµ‹è¯•è„šæœ¬
    print("ğŸ§ª æµ‹è¯•å›¾å®šä¹‰...")
    
    # æµ‹è¯•åŸºç¡€å›¾
    from langchain_core.messages import HumanMessage
    messages = [HumanMessage(content="Add 2 and 3.")]
    result = basic_agent.invoke({"messages": messages})
    print(f"åŸºç¡€å›¾æµ‹è¯•: {result['messages'][-1].content}")
    
    # æµ‹è¯•è®°å¿†å›¾ (æœ¬åœ°æµ‹è¯•éœ€è¦æ·»åŠ checkpointer)
    from langgraph.checkpoint.memory import MemorySaver
    local_memory_graph = create_memory_graph()
    local_memory_graph_with_checkpointer = StateGraph(MessagesState)
    local_memory_graph_with_checkpointer.add_node("assistant", assistant)
    local_memory_graph_with_checkpointer.add_node("tools", ToolNode(tools))
    local_memory_graph_with_checkpointer.add_edge(START, "assistant")
    local_memory_graph_with_checkpointer.add_conditional_edges("assistant", tools_condition)
    local_memory_graph_with_checkpointer.add_edge("tools", "assistant")
    local_memory_compiled = local_memory_graph_with_checkpointer.compile(checkpointer=MemorySaver())
    
    config = {"configurable": {"thread_id": "test"}}
    result = local_memory_compiled.invoke({"messages": messages}, config)
    print(f"è®°å¿†å›¾æµ‹è¯•: {result['messages'][-1].content}")
    
    print("âœ… å›¾å®šä¹‰æ­£å¸¸å·¥ä½œï¼")
